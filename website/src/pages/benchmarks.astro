---
import reverseProxyLatency from "../assets/benchmarks/reverseProxyLatency";
import reverseProxyThroughput from "../assets/benchmarks/reverseProxyThroughput";
import Benchmark from "../components/benchmarks/Benchmark.astro";
import BenchmarkLine from "../components/benchmarks/BenchmarkLine.astro";
import MainLayout from "../layouts/MainLayout.astro";
---

<MainLayout
  title="Benchmarks"
  description="See how Ferron compares to other web servers in terms of performance."
>
  <main
    id="benchmarks"
    class="max-w-screen-xl mx-auto px-4! py-6 md:py-28 flex items-center justify-center flex-col"
  >
    <h1 class="text-4xl md:text-6xl pb-1 md:pb-2 font-bold">Benchmarks</h1>
    <p
      class="max-w-xl text-center text-muted-foreground flex items-center justify-center mt-2 mb-6 md:mb-8 md:text-lg"
    >
      See how Ferron compares to other web servers in terms of performance for
      various use cases.
    </p>
    <h2 class="text-2xl md:text-3xl font-bold mt-6 mb-4 self-start text-start">
      How to read the benchmarks?
    </h2>
    <p class="my-2 text-start self-start text-base md:text-lg">
      Ferron is designed for predictable, high-performance behavior under
      real-world web workloads, including TLS, HTTP/2, connection reuse, and
      high concurrency, rather than for winning isolated microbenchmarks.
    </p>
    <p class="my-2 text-start self-start text-base md:text-lg">
      Ferron also prioritizes correctness, scalability, and modern protocol
      support under extreme concurrency. While it may not always lead in peak
      static file serving throughput, it demonstrates stable performance, and
      strong behavior under load.
    </p>
    <p class="my-2 text-start self-start text-base md:text-lg">
      The results below are grouped according to common deployment scenarios to
      help you evaluate performance in contexts that may match how you would
      actually run Ferron.
    </p>
    <p class="my-2 text-start self-start text-base md:text-lg">
      Note: The static file serving benchmarks focus on medium and large static
      files under HTTP/2, highlighting sustained throughput and backpressure
      behavior rather than small-file protocol overhead.
    </p>
    <h2 class="text-2xl md:text-3xl font-bold mt-6 mb-4 self-start text-start">
      Reverse proxying
    </h2>
    <div class="grid grid-cols-1 lg:grid-cols-2 gap-8">
      <BenchmarkLine
        title="Reverse proxy performance"
        description={'Requests per second when proxying to a "Hello World" Axum application (higher is better)'}
        data={reverseProxyThroughput}
        unit={"req/s"}
        higherIsBetter={true}
        competitors={["Traefik", "HAProxy", "Caddy", "NGINX mainline"]}
        command="h2load -n $(($CONCURRENCY * 100)) -c $CONCURRENCY -t 16 https://localhost"
        date={new Date("2026-01-05")}
        system={"AMD Ryzen 7 8700G, 32GB RAM"}
        linuxVersion={"6.14.0-27-generic"}
        note={'During the NGINX benchmark runs h2load logged "Process Request Failures".'}
      />
      <BenchmarkLine
        title="Latency under load (reverse proxy)"
        description={'Mean response time under high concurrency proxying to a "Hello World" Axum application (lower is better)'}
        data={reverseProxyLatency}
        unit={"ms"}
        higherIsBetter={false}
        competitors={["Traefik", "HAProxy", "Caddy", "NGINX mainline"]}
        command="h2load -n $(($CONCURRENCY * 100)) -c $CONCURRENCY -t 16 https://localhost"
        date={new Date("2026-01-05")}
        system={"AMD Ryzen 7 8700G, 32GB RAM"}
        linuxVersion={"6.14.0-27-generic"}
        note={'During the NGINX benchmark runs h2load logged "Process Request Failures".'}
      />
    </div>
    <div class="grid grid-cols-1 lg:grid-cols-2 lg:gap-8">
      <div class="flex flex-col">
        <h2
          class="text-2xl md:text-3xl font-bold mt-6 mb-4  self-start align-start"
        >
          Static file serving
        </h2>
        <Benchmark
          title="Static file serving"
          description="Requests per second when serving static files (higher is better)"
          data={[
          {
            name: "100KB file",
            ferron: 58593.90,
            competitors: [69325.60, 46405.5, 43178.6, 81833.0],
          },
          {
            name: "1MB file",
            ferron: 6719.40,
            competitors: [7560.50, 9705.0, 6714.30, 9267.50],
          },
          {
            name: "10MB file",
            ferron: 644.80,
            competitors: [718.40, 984.60, 630.70, 945.80],
          }
         ]}
          unit={"req/s"}
          higherIsBetter={true}
          competitors={["Ferron (no io_uring)", "Apache (mpm_event)", "Caddy", "NGINX mainline"]}
          command="h2load --duration 10s -c 100 -t 16 -m 8 https://localhost"
          date={new Date("2026-01-05")}
          system={"AMD Ryzen 7 8700G, 32GB RAM"}
          linuxVersion={"6.14.0-27-generic"}
          note={'During the Apache and NGINX benchmark runs h2load logged "Process Request Failures". For 100 KiB file and NGINX, 1s duration was used instead.'}
          class="grow"
        />
      </div>
      <div class="flex flex-col">
        <h2
          class="text-2xl md:text-3xl font-bold mt-6 mb-4 self-start align-start"
        >
          PHP
        </h2>
        <Benchmark
          title="PHP performance"
          description="Requests per second when serving PHP through PHP-FPM (higher is better)"
          data={[
          {
            name: "Hello World PHP script",
            ferron: 44364.78,
            competitors: [45255.49, 43767.75, 34664.32]
          },
          {
            name: "Fresh WordPress",
            ferron: 223.91,
            competitors: [225.86, 222.74, 223.08]
          }
        ]}
          unit={"req/s"}
          higherIsBetter={true}
          competitors={["lighttpd", "Apache httpd", "Caddy"]}
          command="ferrbench -c 100 -d 60s -t 12 -h https://localhost --http2"
          date={new Date("2025-06-13")}
          system={"AMD Ryzen 5 8600G, 32GB RAM"}
          class="grow"
        />
      </div>
    </div>
    <h2 class="text-2xl md:text-3xl font-bold mt-6 mb-4 self-start text-start">
      Interpreting small differences
    </h2>
    <p class="my-2 text-start self-start text-base md:text-lg">
      In practice, differences on the order of 10â€“20% in synthetic throughput or
      latency benchmarks often translate to little or no perceptible difference
      for end users:
    </p>
    <ul
      class="list-disc list-inside marker:text-muted-foreground my-4 text-start self-start text-base md:text-lg"
    >
      <li>Browsers are limited by network latency and TLS handshakes.</li>
      <li>HTTP/2 and HTTP/3 multiplex requests over shared connections.</li>
      <li>
        Static assets are typically cached at the server, CDN, or browser level.
      </li>
    </ul>
    <p class="my-2 text-start self-start text-base md:text-lg">
      For most real-world deployments, stability under load, worst-case response
      times (for example, 99th percentile response time), and operational
      simplicity have a greater impact than small throughput differences
      measured in isolation.
    </p>
  </main>
</MainLayout>
